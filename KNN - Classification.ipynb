{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "\n",
    "    collection = {}\n",
    "    docId = 1\n",
    "    classes = []\n",
    "\n",
    "    for folder in os.listdir(\"C:/Users/Areeka Aijaz/Desktop/IR Assignment 3/bbcsport\"):\n",
    "\n",
    "        N = 0\n",
    "        \n",
    "        if not folder.endswith(\".TXT\"):\n",
    "            folderPath = 'C:/Users/Areeka Aijaz/Desktop/IR Assignment 3/bbcsport/' + folder\n",
    "\n",
    "            for document in os.listdir(folderPath):\n",
    "                N += 1\n",
    "                collection[docId] = []\n",
    "                docPath = folderPath + '/' + document\n",
    "                tokens = tokenize(docPath)\n",
    "                collection[docId].extend(tokens)\n",
    "                docId += 1\n",
    "\n",
    "            classes.append((folder,N))\n",
    "                \n",
    "    return len(collection),collection,classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docPath):\n",
    "    \n",
    "    symbols = ['$','[',']','.','?',';',':','-','!','--',',','...','0','1','2','3','4','5','6','7','8','9','\\\\','\"','(',')','{','}','%','&','/','',\"'re\",\"n't\",\"'s\",\"'ve\",\"'d\",\"'m\"]\n",
    "\n",
    "    nt_symbols = ['-','.',']',\"n't\",'--','...']\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    flag = False\n",
    "    \n",
    "    doc = open(docPath,'r')\n",
    "\n",
    "    for line in doc:\n",
    "        \n",
    "        for word in line.split():\n",
    "            \n",
    "            for sym in symbols:\n",
    "                if sym in word and sym not in nt_symbols:\n",
    "                    word = word.replace(sym,'')\n",
    "\n",
    "            if word != '' and word[len(word)-1] == '.':\n",
    "                word = word.replace('.','')\n",
    "\n",
    "            if '-' in word :\n",
    "                word = re.split(r'[-.]',word)\n",
    "                flag = True\n",
    "\n",
    "            if flag:\n",
    "                tokens.extend(word)\n",
    "                flag = False\n",
    "            else:\n",
    "                tokens.append(word)    \n",
    "            \n",
    "    preProcessedTokens = pre_processing(tokens)\n",
    "            \n",
    "    doc.close()\n",
    "    \n",
    "    return preProcessedTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(tokens):\n",
    "    \n",
    "    stopWordsList = ['a','is','the','of','all','and','to','can','be','as','once','for','at','am','are','have','had','up','his','her','in','on','we','do','']\n",
    "    \n",
    "    preProcessedToken = []\n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    #lemm = WordNetLemmatizer()\n",
    "    \n",
    "    for word in tokens:\n",
    "        if word.casefold() not in stopWordsList:\n",
    "            word = word.casefold()\n",
    "            word = ps.stem(word)\n",
    "            #word = lemm.lemmatize(word)\n",
    "            preProcessedToken.append(word)\n",
    "        \n",
    "    return preProcessedToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(collection):\n",
    "\n",
    "    dictionary = []\n",
    "\n",
    "    for i in collection:\n",
    "        for term in collection[i] :\n",
    "            if term not in dictionary and term.isalpha() and len(term)>2:\n",
    "                dictionary.append(term)\n",
    "\n",
    "    dictionary.sort()\n",
    "    \n",
    "    return dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf(collection, dictionary):\n",
    "    \n",
    "    termFrequency = {}\n",
    "\n",
    "    for token in dictionary:\n",
    "        termFrequency[token] = []\n",
    "\n",
    "        for i in collection:\n",
    "            termFrequency[token].append(collection[i].count(token))\n",
    "    \n",
    "    return termFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf(termFrequency, N):\n",
    "\n",
    "    documentFrequency = {}\n",
    "\n",
    "    for term in termFrequency:   \n",
    "        documentFrequency[term] = 0\n",
    "\n",
    "        for count in termFrequency[term]:\n",
    "            if count > 0:\n",
    "                documentFrequency[term] += 1\n",
    "\n",
    "    idf = {}\n",
    "\n",
    "    for term in documentFrequency:\n",
    "        idf[term] = math.log10(N/documentFrequency[term])\n",
    "        \n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_scoring(termFrequency, idf):\n",
    "\n",
    "    docScore = {}\n",
    "\n",
    "    for term in termFrequency:\n",
    "        docScore[term] = []\n",
    "\n",
    "        for tf in termFrequency[term]:\n",
    "            docScore[term].append(tf*idf[term])\n",
    "\n",
    "    return docScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "documentVector = [\n",
    "    doc1 = ([score[term1],score[term2],...,score[term n]], class a)\n",
    "    doc2 = ([score[term1],score[term2],...,score[term n]], class b)\n",
    "    .....\n",
    "    docN = ([score[term1],score[term2],...,score[term n]], class x)\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def get_document_vector(N,docScore,classes):\n",
    "    \n",
    "    documentVector = []\n",
    "    k = 0\n",
    "    j = classes[0][1]\n",
    "    \n",
    "    for i in range(N):\n",
    "        document = []\n",
    "        \n",
    "        for term in docScore:\n",
    "            document.append(docScore[term][i])\n",
    "        \n",
    "        if i < j :\n",
    "            documentVector.append((document,classes[k][0]))\n",
    "        else:\n",
    "            j = classes[k+1][1] + i\n",
    "            k += 1\n",
    "            documentVector.append((document,classes[k][0]))\n",
    "        \n",
    "    return documentVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(documentVector, N, classes):\n",
    "    \n",
    "    #Following documents will be used in testing set\n",
    "    #Hard coded so that results will be stored in file KNN.txt to minimize throughput time \n",
    "    testDoc = [2, 4, 8, 9, 11, 16, 22, 26, 29, 33, 36, 37, 43, 46, 48, 51, 52, 57, 62, 65, 68, 72, 76, 79, 81, 82, 85, 90, 91, 94, 105, 108, 109, 111, 112, 114, 117, 119, 120, 122, 125, 132, 138, 144, 147, 151, 152, 153, 155, 156, 158, 173, 174, 175, 176, 184, 188, 192, 193, 198, 204, 209, 210, 213, 221, 222, 224, 228, 229, 230, 233, 239, 241, 246, 250, 252, 257, 259, 261, 275, 277, 279, 280, 283, 286, 287, 290, 292, 293, 295, 296, 298, 303, 306, 308, 309, 310, 313, 315, 323, 326, 327, 329, 330, 334, 340, 341, 347, 350, 352, 354, 361, 363, 369, 371, 375, 378, 379, 382, 391, 398, 403, 405, 409, 413, 419, 423, 424, 426, 431, 434, 437, 438, 439, 440, 442, 444, 446, 447, 449, 452, 459, 462, 464, 475, 487, 494, 495, 496, 498, 500, 506, 510, 522, 523, 531, 532, 533, 541, 543, 545, 551, 556, 557, 558, 560, 564, 568, 576, 577, 586, 590, 595, 603, 607, 610, 612, 614, 615, 617, 618, 619, 623, 624, 625, 626, 628, 630, 632, 634, 639, 645, 646, 648, 651, 652, 653, 656, 659, 669, 673, 677, 681, 686, 688, 690, 696, 698, 702, 705, 708, 709, 711, 714, 720, 722, 725, 726, 728, 735]\n",
    "    \n",
    "    #Following commented code is for generating random documents for test set, \n",
    "    #For using following code, file KNN.txt should be deleted manually from directory each time before running code\n",
    "    #Classification will take atleast 10 minutes if generating random test set each time\n",
    "    \"\"\"\"\n",
    "    testDoc = []\n",
    "    n = 0\n",
    "    \n",
    "    for i in range(len(classes)):\n",
    "        splitCount = int(classes[i][1]*0.3)\n",
    "        testDoc.extend(random.sample(range(n+1, classes[i][1]+n), splitCount))\n",
    "        n += classes[i][1]\n",
    "        \n",
    "    testDoc.sort()\n",
    "    \"\"\"\n",
    "    \n",
    "    testSet = []\n",
    "    trainSet = []\n",
    "    \n",
    "    for i in range(len(documentVector)):\n",
    "        \n",
    "        if i not in testDoc:\n",
    "            trainSet.append(documentVector[i])\n",
    "            \n",
    "        else:\n",
    "            testSet.append(documentVector[i])    \n",
    "    \n",
    "    return trainSet,testSet, testDoc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(trainingSet, testingSet):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    actual_labels = []\n",
    "    \n",
    "    k_labels = []\n",
    "    \n",
    "    if os.path.isfile('KNN.txt'):\n",
    "        KNN = open('KNN.txt','r')\n",
    "        \n",
    "        for i in range(len(testingSet)):\n",
    "            actual_labels.append(testingSet[i][1])\n",
    "            \n",
    "        for word in KNN:\n",
    "            predicted_labels.append(word[:-1])\n",
    "            \n",
    "        KNN.close()\n",
    "        \n",
    "    else:\n",
    "        KNN = open('KNN.txt','a')\n",
    "        \n",
    "        for i in range(len(testingSet)):\n",
    "            cosSim = [] \n",
    "            actual_labels.append(testingSet[i][1])\n",
    "\n",
    "            for j in range(len(trainingSet)): \n",
    "                cosSim.append(((dot(trainingSet[j][0], testingSet[i][0])/(norm(trainingSet[j][0])*norm(testingSet[i][0]))), trainingSet[j][1]))\n",
    "\n",
    "            cosSim.sort(reverse = True)\n",
    "\n",
    "            k_labels = cosSim[0:3]                    \n",
    "\n",
    "            if (k_labels[0][1] == k_labels[1][1] == k_labels[2][1]) or (k_labels[2][1] == k_labels[1][1]) or (k_labels[0][1] == k_labels[2][1]) or (k_labels[0][1] != k_labels[1][1] != k_labels[2][1]):\n",
    "                                   predicted_labels.append(k_labels[2][1])\n",
    "\n",
    "            elif k_labels[0][1] == k_labels[1][1]:\n",
    "                                   predicted_labels.append(k_labels[1][1])   \n",
    "                    \n",
    "        \n",
    "            KNN.write(predicted_labels[i] + '\\n')\n",
    "        \n",
    "        KNN.close()\n",
    "        \n",
    "    return actual_labels, predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(actual_label,predicted_label):\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "\n",
    "    for i in range(len(actual_label)):\n",
    "            if actual_label[i] == predicted_label[i]:\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect += 1           \n",
    "\n",
    "    print('Correct :',correct)\n",
    "    print('Incorrect :',incorrect)\n",
    "    print('Accuracy :',correct/len(actual_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    N,collection,classes = read_file()\n",
    "    dictionary = make_dictionary(collection)\n",
    "    termFrequency = calculate_tf(collection,dictionary)\n",
    "    idf = calculate_idf(termFrequency,N)\n",
    "    docScore = tf_idf_scoring(termFrequency, idf)\n",
    "    documentVector = get_document_vector(N,docScore,classes)\n",
    "    trainingSet, testingSet, testingDocumentsNo = split_dataset(documentVector,N, classes)\n",
    "    actual_label, predicted_label = classification(trainingSet, testingSet)\n",
    "    \n",
    "    actualLabels = pd.DataFrame({'Actual Label' : actual_label})\n",
    "    predictedLabels = pd.DataFrame({'Predicted Label' : predicted_label})\n",
    "    testDoc = pd.DataFrame({'Test Documents' : testingDocumentsNo})\n",
    "    result = testDoc.join(actualLabels).join(predictedLabels) \n",
    "    print(result)\n",
    "    \n",
    "    check_accuracy(actual_label,predicted_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Test Documents Actual Label Predicted Label\n",
      "0                 2    athletics       athletics\n",
      "1                 4    athletics       athletics\n",
      "2                 8    athletics       athletics\n",
      "3                 9    athletics       athletics\n",
      "4                11    athletics       athletics\n",
      "5                16    athletics       athletics\n",
      "6                22    athletics       athletics\n",
      "7                26    athletics       athletics\n",
      "8                29    athletics       athletics\n",
      "9                33    athletics       athletics\n",
      "10               36    athletics       athletics\n",
      "11               37    athletics       athletics\n",
      "12               43    athletics       athletics\n",
      "13               46    athletics       athletics\n",
      "14               48    athletics       athletics\n",
      "15               51    athletics       athletics\n",
      "16               52    athletics       athletics\n",
      "17               57    athletics       athletics\n",
      "18               62    athletics       athletics\n",
      "19               65    athletics       athletics\n",
      "20               68    athletics       athletics\n",
      "21               72    athletics       athletics\n",
      "22               76    athletics       athletics\n",
      "23               79    athletics       athletics\n",
      "24               81    athletics       athletics\n",
      "25               82    athletics       athletics\n",
      "26               85    athletics       athletics\n",
      "27               90    athletics       athletics\n",
      "28               91    athletics       athletics\n",
      "29               94    athletics       athletics\n",
      "..              ...          ...             ...\n",
      "190             639        rugby          tennis\n",
      "191             645       tennis          tennis\n",
      "192             646       tennis          tennis\n",
      "193             648       tennis          tennis\n",
      "194             651       tennis          tennis\n",
      "195             652       tennis          tennis\n",
      "196             653       tennis          tennis\n",
      "197             656       tennis          tennis\n",
      "198             659       tennis          tennis\n",
      "199             669       tennis          tennis\n",
      "200             673       tennis          tennis\n",
      "201             677       tennis          tennis\n",
      "202             681       tennis          tennis\n",
      "203             686       tennis          tennis\n",
      "204             688       tennis          tennis\n",
      "205             690       tennis          tennis\n",
      "206             696       tennis          tennis\n",
      "207             698       tennis          tennis\n",
      "208             702       tennis          tennis\n",
      "209             705       tennis          tennis\n",
      "210             708       tennis          tennis\n",
      "211             709       tennis          tennis\n",
      "212             711       tennis          tennis\n",
      "213             714       tennis          tennis\n",
      "214             720       tennis          tennis\n",
      "215             722       tennis          tennis\n",
      "216             725       tennis          tennis\n",
      "217             726       tennis          tennis\n",
      "218             728       tennis          tennis\n",
      "219             735       tennis          tennis\n",
      "\n",
      "[220 rows x 3 columns]\n",
      "Correct : 217\n",
      "Incorrect : 3\n",
      "Accuracy : 0.9863636363636363\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "#Running code first time will take 10 to 15 minutes, then next time it will take 3 to 4 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
